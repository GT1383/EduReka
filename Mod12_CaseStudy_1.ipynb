{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "553f2ff4-b74c-4e16-ac78-9124a28986b0",
   "metadata": {},
   "source": [
    "#### Module 12: Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba06770-53ae-4364-8e78-49848d50bb9a",
   "metadata": {},
   "source": [
    "#### Case Study–1\n",
    "\n",
    "Domain – Logistics\n",
    "\n",
    "focus – Optimal path\n",
    "\n",
    "Business challenge/requirement\n",
    "\n",
    "BluEx is a leading logistics company in India. It's known for efficient delivery of packets to customers. However, BluEx is facing a challenge where its van drivers are taking a suboptimal path for delivery. This is causing delays and higher fuel costs.\n",
    "You as an ML expert have to create an ML model using Reinforcement Learning so that an efficient path is found through the program.\n",
    "\n",
    "Key issues \n",
    "\n",
    "Data has lots of attributes and classification could be tricky\n",
    "\n",
    "Considerations\n",
    "\n",
    "Reinforcement Learning is tricky, so the expectation is to come up with a sample flow and full-fledged implementation will be done by the team later\n",
    "\n",
    "Data volume\n",
    "\n",
    "- None. Sample data is hard coded in the program\n",
    "\n",
    "Additional information\n",
    "\n",
    "- NA\n",
    "\n",
    "Business benefits\n",
    "\n",
    "Up to 15% of fuel cost can be saved by taking the optimal path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dcde07-f8f6-489d-9f22-aec349b2c307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned path: [(0, 0), (0, 1), (0, 2), (0, 3), (1, 3), (2, 3), (3, 3)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Grid world (0 = free, 1 = obstacle)\n",
    "GRID = np.array([\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 1, 0]\n",
    "])\n",
    "\n",
    "START = (0, 0)\n",
    "GOAL = (3, 3)\n",
    "ACTIONS = [(0,1), (0,-1), (1,0), (-1,0)]  # Right, Left, Down, Up\n",
    "\n",
    "# Rewards\n",
    "STEP_REWARD = -1\n",
    "OBSTACLE_PENALTY = -5\n",
    "GOAL_REWARD = 10\n",
    "\n",
    "# Q-table\n",
    "Q = np.zeros((GRID.shape[0], GRID.shape[1], len(ACTIONS)))\n",
    "\n",
    "def step(state, action):\n",
    "    r, c = state\n",
    "    dr, dc = action\n",
    "    nr, nc = r+dr, c+dc\n",
    "    if nr<0 or nr>=GRID.shape[0] or nc<0 or nc>=GRID.shape[1] or GRID[nr,nc]==1:\n",
    "        return state, OBSTACLE_PENALTY, False\n",
    "    if (nr,nc)==GOAL:\n",
    "        return (nr,nc), GOAL_REWARD, True\n",
    "    return (nr,nc), STEP_REWARD, False\n",
    "\n",
    "# Training\n",
    "for ep in range(500):\n",
    "    state = START\n",
    "    done = False\n",
    "    while not done:\n",
    "        a = random.randint(0,3)\n",
    "        next_state, reward, done = step(state, ACTIONS[a])\n",
    "        r,c = state\n",
    "        nr,nc = next_state\n",
    "        Q[r,c,a] += 0.1*(reward + 0.9*np.max(Q[nr,nc]) - Q[r,c,a])\n",
    "        state = next_state\n",
    "\n",
    "# Extract path\n",
    "path = [START]\n",
    "state = START\n",
    "for _ in range(20):\n",
    "    r,c = state\n",
    "    a = np.argmax(Q[r,c])\n",
    "    state, _, done = step(state, ACTIONS[a])\n",
    "    path.append(state)\n",
    "    if done: break\n",
    "\n",
    "print(\"Learned path:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c8c05-4801-4906-b353-9661b60a1c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
