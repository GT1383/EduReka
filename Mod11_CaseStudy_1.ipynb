{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "553f2ff4-b74c-4e16-ac78-9124a28986b0",
   "metadata": {},
   "source": [
    "#### Module 11: Association Rules Mining and Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba06770-53ae-4364-8e78-49848d50bb9a",
   "metadata": {},
   "source": [
    "#### Case Study–1\n",
    "\n",
    "Domain –Retail\n",
    "\n",
    "focus – Optimize Book RENT\n",
    "\n",
    "Business challenge/requirement\n",
    "\n",
    "BookRent is the largest online and offline book rental chain in India. The Company charges a fixed fee per month plus rental per book. So, the company makes more money when users rent more books. You as an ML expert have to model a recommendation engine so that user gets\n",
    "recommendation of books based on the behavior of similar users. This will ensure that users are renting books based on their taste.\n",
    "The company is still unprofitable and is looking to improve both revenue and profit.\n",
    "\n",
    "\n",
    "Key issues\n",
    "\n",
    "As of now a lot of users return the books and do not take the new rental. The right recommendation will entice a users to rent more books\n",
    "\n",
    "Considerations\n",
    "\n",
    "NONE\n",
    "\n",
    "Data volume\n",
    "\n",
    "- Approx 1 M records – file BX-Book-Ratings.csv and 2 more. But only 10K records will be used\n",
    "\n",
    "Fields in Data\n",
    "\n",
    "• user_id: Unique Id of the User\n",
    "\n",
    "• isbn: International Standard Book Number is a unique numeric commercial book identifier\n",
    "\n",
    "• rating: the rating given by the user\n",
    "\n",
    "Business benefits\n",
    "\n",
    "Increase in both top line and bottom line as more rentals per user means more revenue and more profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2eecb4c-2a9d-47f4-a672-1719517f42d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['isbn', 'book_title'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m ratings \u001b[38;5;241m=\u001b[39m ratings\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Step 4: Merge ratings with book titles\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# BX-Books usually has 'isbn' and 'book_title' after normalization\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m books_small \u001b[38;5;241m=\u001b[39m books[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misbn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbook_title\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[0;32m     19\u001b[0m ratings \u001b[38;5;241m=\u001b[39m ratings\u001b[38;5;241m.\u001b[39mmerge(books_small, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misbn\u001b[39m\u001b[38;5;124m\"\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Step 5: Create user-item matrix\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['isbn', 'book_title'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Step 1: Load datasets\n",
    "ratings = pd.read_csv(\"BX-Book-Ratings.csv\", sep=\";\", encoding=\"latin-1\", on_bad_lines=\"skip\")\n",
    "books = pd.read_csv(\"BX-Books.csv\", sep=\";\", encoding=\"latin-1\", on_bad_lines=\"skip\")\n",
    "\n",
    "# Step 2: Normalize column names (lowercase, replace spaces/hyphens with underscores)\n",
    "ratings.columns = ratings.columns.str.strip().str.lower().str.replace(\" \", \"_\").str.replace(\"-\", \"_\")\n",
    "books.columns = books.columns.str.strip().str.lower().str.replace(\" \", \"_\").str.replace(\"-\", \"_\")\n",
    "\n",
    "# Step 3: Use only 10k ratings\n",
    "ratings = ratings.sample(n=10000, random_state=42)\n",
    "\n",
    "# Step 4: Merge ratings with book titles\n",
    "# BX-Books usually has 'isbn' and 'book_title' after normalization\n",
    "books_small = books[[\"isbn\", \"book_title\"]].drop_duplicates()\n",
    "ratings = ratings.merge(books_small, on=\"isbn\", how=\"left\")\n",
    "\n",
    "# Step 5: Create user-item matrix\n",
    "user_item = ratings.pivot_table(index=\"user_id\", columns=\"isbn\", values=\"book_rating\")\n",
    "user_item_filled = user_item.fillna(0)\n",
    "\n",
    "# Step 6: Compute cosine similarity between users\n",
    "similarity = cosine_similarity(user_item_filled)\n",
    "similarity_df = pd.DataFrame(similarity, index=user_item_filled.index, columns=user_item_filled.index)\n",
    "\n",
    "# Step 7: Recommend books for a user\n",
    "def recommend_books(user_id, top_n=5):\n",
    "    # Find most similar users\n",
    "    similar_users = similarity_df[user_id].sort_values(ascending=False).index[1:6]\n",
    "    \n",
    "    # Average ratings from similar users\n",
    "    sim_user_ratings = user_item.loc[similar_users].mean().sort_values(ascending=False)\n",
    "    \n",
    "    # Exclude books already rated by target user\n",
    "    rated_books = user_item.loc[user_id].dropna().index\n",
    "    recommendations = sim_user_ratings.drop(rated_books).head(top_n)\n",
    "    \n",
    "    # Map ISBNs to titles\n",
    "    return books_small.set_index(\"isbn\").loc[recommendations.index][\"book_title\"].tolist()\n",
    "\n",
    "# Step 8: Demo for a sample user\n",
    "sample_user = user_item.index[0]\n",
    "print(f\"Top 5 recommendations for user {sample_user}:\")\n",
    "print(recommend_books(sample_user))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dcde07-f8f6-489d-9f22-aec349b2c307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
